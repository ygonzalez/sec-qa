{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from langchain.text_splitter import TextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Weaviate\n",
    "from langchain.schema import Document\n",
    "import weaviate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "WEAVIATE_API_KEY = os.getenv('WEAVIATE_API_KEY2')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Docs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('top_50')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 31min 46s, sys: 4min, total: 1h 35min 47s\n",
      "Wall time: 2h 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%time pages = loader.load()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "42"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Splitting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class CustomTextSplitter(TextSplitter):\n",
    "\n",
    "    def split_text(self, document):\n",
    "        text = document.page_content\n",
    "\n",
    "        metadata = {\n",
    "            \"company\": self.extract_metadata(r'COMPANY CONFORMED NAME:\\s*([^\\n]+)', text),\n",
    "            \"date\": self.extract_metadata(r'FILED AS OF DATE:\\s*(\\d+)', text),\n",
    "            \"sic\": self.extract_metadata(r'STANDARD INDUSTRIAL CLASSIFICATION:\\s*([^\\n]+)', text),\n",
    "            \"state\": self.extract_metadata(r'STATE:\\s*([^\\n]+)', text)\n",
    "        }\n",
    "\n",
    "        ten_k_text = self.extract_10k(text)\n",
    "\n",
    "        sections_df = self.get_sections_dataframe(ten_k_text)\n",
    "        # display(sections_df)\n",
    "\n",
    "        return self.extract_cleaned_sections(ten_k_text, sections_df, metadata)\n",
    "\n",
    "    def extract_metadata(self, pattern, text):\n",
    "        match = re.search(pattern, text)\n",
    "        return match.group(1).strip() if match else None\n",
    "\n",
    "    def extract_10k(self, text):\n",
    "        doc_start_pattern = re.compile(r'<DOCUMENT>')\n",
    "        doc_end_pattern = re.compile(r'</DOCUMENT>')\n",
    "        type_pattern = re.compile(r'<TYPE>[^\\n]+')\n",
    "\n",
    "        doc_start_is = [x.end() for x in doc_start_pattern.finditer(text)]\n",
    "        doc_end_is = [x.start() for x in doc_end_pattern.finditer(text)]\n",
    "        doc_types = [x[len('<TYPE>'):] for x in type_pattern.findall(text)]\n",
    "\n",
    "        for doc_type, doc_start, doc_end in zip(doc_types, doc_start_is, doc_end_is):\n",
    "            if doc_type == '10-K':\n",
    "                return text[doc_start:doc_end]\n",
    "\n",
    "        return None\n",
    "\n",
    "    def get_sections_dataframe(self, ten_k_text):\n",
    "        regex = re.compile(r'(>Item(\\s|&#160;|&nbsp;)(1.|1A|1B|2|3|4|5|6|7.|7A|8.|9A|9B|9.|[1][0-5])\\.{0,1})|(ITEM(\\s|&#160;|&nbsp;)(1.|1A|1B|2|3|4|5|6|7.|7A|8.|9A|9B|9.|[1][0-5])\\.{0,1})')\n",
    "        matches = regex.finditer(ten_k_text)\n",
    "\n",
    "        df = pd.DataFrame([(x.group(), x.start(), x.end()) for x in matches], columns=['item', 'start', 'end'])\n",
    "        df['item'] = df['item'].str.lower().str.replace('&#160;|&nbsp;| |\\.', '', regex=True).str.replace('>', '', regex=False)\n",
    "\n",
    "        # Filter for the last occurrence of each section\n",
    "        df = df.groupby('item').last().reset_index()\n",
    "\n",
    "        # Map sections to a predefined order\n",
    "        section_order = {\n",
    "            'item1': 1, 'item1a': 2, 'item1b': 3, 'item2': 4, 'item3': 5, 'item4': 6,\n",
    "            'item5': 7, 'item6': 8, 'item7': 9, 'item7a': 10, 'item8': 11, 'item9': 12,\n",
    "            'item9a': 13, 'item9b': 14, 'item9c': 15, 'item10': 16, 'item11': 17, 'item12': 18,\n",
    "            'item13': 19, 'item14': 20, 'item15': 21, 'item16': 22\n",
    "        }\n",
    "        df['order'] = df['item'].map(section_order)\n",
    "\n",
    "        # Sort by predefined order\n",
    "        return df.sort_values(by=['order']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    def extract_cleaned_sections(self, ten_k_text, sections_df, metadata):\n",
    "        sections = ['item1', 'item1a', 'item1b', 'item2', 'item3', 'item4', 'item5', 'item6', 'item7',\n",
    "                    'item7a', 'item8', 'item9', 'item9a', 'item9b', 'item9c', 'item10', 'item11', 'item12',\n",
    "                    'item13', 'item14', 'item15', 'item16']\n",
    "        section_titles = {\n",
    "                    'item1': 'Business',\n",
    "                    'item1a': 'Risk Factors',\n",
    "                    'item1b': 'Unresolved Staff Comments',\n",
    "                    'item2': 'Properties',\n",
    "                    'item3': 'Legal Proceedings',\n",
    "                    'item4': 'Mine Safety Disclosures',\n",
    "                    'item5': 'Market for Registrant’s Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities',\n",
    "                    'item6': 'Selected Financial Data',\n",
    "                    'item7': 'Management’s Discussion and Analysis of Financial Condition and Results of Operations',\n",
    "                    'item7a': 'Quantitative and Qualitative Disclosures About Market Risk',\n",
    "                    'item8': 'Financial Statements and Supplementary Data',\n",
    "                    'item9': 'Changes in and Disagreements With Accountants on Accounting and Financial Disclosure',\n",
    "                    'item9a': 'Controls and Procedures',\n",
    "                    'item9b': 'Other Information',\n",
    "                    'item10': 'Directors, Executive Officers and Corporate Governance',\n",
    "                    'item11': 'Executive Compensation',\n",
    "                    'item12': 'Security Ownership of Certain Beneficial Owners and Management and Related Stockholder Matters',\n",
    "                    'item13': 'Certain Relationships and Related Transactions, and Director Independence',\n",
    "                    'item14': 'Principal Accountant Fees and Services',\n",
    "                    'item15': 'Exhibits and Financial Statement Schedules',\n",
    "                    'item16': 'Form 10-K Summary'\n",
    "                }\n",
    "\n",
    "        cleaned_sections = []\n",
    "\n",
    "        for index, section_name in enumerate(sections[:-1]):  # We use -1 because we don't need to process the last item separately\n",
    "            current_start_values = sections_df[sections_df['item'] == section_name]['start'].values\n",
    "            if len(current_start_values) == 0:  # section_name not found in the dataframe\n",
    "                continue\n",
    "            current_start = current_start_values[0]\n",
    "\n",
    "            # Adjusting for the next section's start\n",
    "            if index + 1 < len(sections):\n",
    "                next_start_values = sections_df[sections_df['item'] == sections[index+1]]['start'].values\n",
    "                if len(next_start_values) == 0:  # next section name not found in the dataframe\n",
    "                    next_start = len(ten_k_text)\n",
    "                else:\n",
    "                    next_start = next_start_values[0]\n",
    "            else:\n",
    "                next_start = len(ten_k_text)\n",
    "\n",
    "            section_title = section_titles.get(section_name, \"\")\n",
    "            section_content = ten_k_text[current_start:next_start]\n",
    "\n",
    "            current_metadata = metadata.copy()\n",
    "            current_metadata[\"title\"] = section_title\n",
    "\n",
    "            content = BeautifulSoup(section_content, \"lxml\").get_text(\"\\n\\n\")\n",
    "\n",
    "            cleaned_sections.append({\n",
    "                \"content\": content,\n",
    "                \"metadata\": current_metadata\n",
    "            })\n",
    "\n",
    "        return cleaned_sections"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "custom_splitter = CustomTextSplitter()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Split on sections of the 10-k\n",
    "sections = []\n",
    "for page in pages:\n",
    "    transformed_doc = custom_splitter.split_text(page)\n",
    "    sections.extend(transformed_doc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Break up sections into chunks\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 200\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "# Create an empty list to store the documents\n",
    "documents = []\n",
    "\n",
    "# Iterate over the sections and split large sections into smaller chunks\n",
    "for section in sections:\n",
    "    if len(section['content']) > chunk_size:\n",
    "        chunks = text_splitter.split_text(section['content'])\n",
    "        # Append the section's metadata to each chunk\n",
    "        for chunk in chunks:\n",
    "            modified_chunk = {\n",
    "                \"content\": chunk,\n",
    "                \"metadata\": section[\"metadata\"]\n",
    "            }\n",
    "            # Create a Document object for each chunk and add it to the documents list\n",
    "            document = Document(page_content=modified_chunk['content'], metadata=modified_chunk['metadata'])\n",
    "            documents.append(document)\n",
    "    else:\n",
    "        # Create a Document object for the section and add it to the documents list\n",
    "        document = Document(page_content=section['content'], metadata=section['metadata'])\n",
    "        documents.append(document)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "29185"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "Document(page_content='>Item\\xa01.\\xa0\\xa0\\xa0\\xa0Business\\n\\nGeneral\\n\\nVerizon\\n\\nCommunications Inc. (the Company) is a holding company that, acting through its subsidiaries (together with the Company, collectively, Verizon), is one of the world’s leading providers of communications, technology, information and entertainment products and services to consumers, businesses and government entities.\\n\\nWith a presence around the world, we offer data, video and voice services and solutions on our networks and platforms that are designed to meet customers’ demand for mobility, reliable network connectivity, security and control.\\n\\nOur principal executive offices are located at 1095 Avenue of the Americas, New York, New York 10036 (telephone number 212-395-1000).\\n\\nWe have two reportable segments that we operate and manage as strategic business units - Verizon Consumer Group (Consumer) and Verizon Business Group (Business).\\n\\nVerizon Consumer Group', metadata={'company': 'VERIZON COMMUNICATIONS INC', 'date': '20230210', 'sic': 'TELEPHONE COMMUNICATIONS (NO RADIO TELEPHONE) [4813]', 'state': 'NY', 'title': 'Business'})"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vector Store"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "auth_config = weaviate.AuthApiKey(api_key=WEAVIATE_API_KEY)  # Replace w/ your Weaviate instance API key\n",
    "\n",
    "# Instantiate the client\n",
    "client = weaviate.Client(\n",
    "    url=\"https://sec-weaviate-4syafahy.weaviate.network\", # Replace w/ your Weaviate cluster URL\n",
    "    auth_client_secret=auth_config,\n",
    "    additional_headers={\n",
    "        \"X-OpenAI-Api-Key\": \"YOUR-OPENAI-API-KEY\", # Replace with your OpenAI key\n",
    "        }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.is_ready()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 922745 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 842408 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 884731 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 921746 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 845081 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 903027 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 826407 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 868071 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 928900 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 854219 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 891699 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 926472 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 851599 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 877914 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 894468 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 926297 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 850884 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 847827 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 872345 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 935104 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 858548 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 899892 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 820649 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 866501 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 833059 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 862315 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 905885 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 831028 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 893961 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 819131 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 876873 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 800386 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "Schema could not be retrieved.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mConnectionResetError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001B[0m in \u001B[0;36murlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    702\u001B[0m             \u001B[0;31m# Make the request on the httplib connection object.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 703\u001B[0;31m             httplib_response = self._make_request(\n\u001B[0m\u001B[1;32m    704\u001B[0m                 \u001B[0mconn\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001B[0m in \u001B[0;36m_make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    448\u001B[0m                     \u001B[0;31m# Otherwise it looks like a bug in the code.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 449\u001B[0;31m                     \u001B[0msix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    450\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mSocketTimeout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mBaseSSLError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSocketError\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/urllib3/packages/six.py\u001B[0m in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001B[0m in \u001B[0;36m_make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    443\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 444\u001B[0;31m                     \u001B[0mhttplib_response\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetresponse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    445\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/http/client.py\u001B[0m in \u001B[0;36mgetresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1376\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1377\u001B[0;31m                 \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbegin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1378\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mConnectionError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/http/client.py\u001B[0m in \u001B[0;36mbegin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    319\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 320\u001B[0;31m             \u001B[0mversion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstatus\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreason\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_read_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    321\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mstatus\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mCONTINUE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/http/client.py\u001B[0m in \u001B[0;36m_read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    280\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_read_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 281\u001B[0;31m         \u001B[0mline\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreadline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_MAXLINE\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"iso-8859-1\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    282\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mline\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0m_MAXLINE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/socket.py\u001B[0m in \u001B[0;36mreadinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    703\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 704\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv_into\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    705\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/ssl.py\u001B[0m in \u001B[0;36mrecv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1241\u001B[0m                   self.__class__)\n\u001B[0;32m-> 1242\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnbytes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1243\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/ssl.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1099\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mbuffer\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1100\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sslobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1101\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mConnectionResetError\u001B[0m: [Errno 54] Connection reset by peer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mProtocolError\u001B[0m                             Traceback (most recent call last)",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/requests/adapters.py\u001B[0m in \u001B[0;36msend\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    485\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 486\u001B[0;31m             resp = conn.urlopen(\n\u001B[0m\u001B[1;32m    487\u001B[0m                 \u001B[0mmethod\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001B[0m in \u001B[0;36murlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    786\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 787\u001B[0;31m             retries = retries.increment(\n\u001B[0m\u001B[1;32m    788\u001B[0m                 \u001B[0mmethod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merror\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_pool\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_stacktrace\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexc_info\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/urllib3/util/retry.py\u001B[0m in \u001B[0;36mincrement\u001B[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001B[0m\n\u001B[1;32m    549\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mread\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mFalse\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_is_method_retryable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmethod\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 550\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0msix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreraise\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merror\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merror\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_stacktrace\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    551\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mread\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/urllib3/packages/six.py\u001B[0m in \u001B[0;36mreraise\u001B[0;34m(tp, value, tb)\u001B[0m\n\u001B[1;32m    768\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mtb\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 769\u001B[0;31m                 \u001B[0;32mraise\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    770\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001B[0m in \u001B[0;36murlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    702\u001B[0m             \u001B[0;31m# Make the request on the httplib connection object.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 703\u001B[0;31m             httplib_response = self._make_request(\n\u001B[0m\u001B[1;32m    704\u001B[0m                 \u001B[0mconn\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001B[0m in \u001B[0;36m_make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    448\u001B[0m                     \u001B[0;31m# Otherwise it looks like a bug in the code.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 449\u001B[0;31m                     \u001B[0msix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    450\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mSocketTimeout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mBaseSSLError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSocketError\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/urllib3/packages/six.py\u001B[0m in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001B[0m in \u001B[0;36m_make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    443\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 444\u001B[0;31m                     \u001B[0mhttplib_response\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetresponse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    445\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mBaseException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/http/client.py\u001B[0m in \u001B[0;36mgetresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1376\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1377\u001B[0;31m                 \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbegin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1378\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mConnectionError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/http/client.py\u001B[0m in \u001B[0;36mbegin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    319\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 320\u001B[0;31m             \u001B[0mversion\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstatus\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreason\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_read_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    321\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mstatus\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mCONTINUE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/http/client.py\u001B[0m in \u001B[0;36m_read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    280\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_read_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 281\u001B[0;31m         \u001B[0mline\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreadline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_MAXLINE\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"iso-8859-1\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    282\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mline\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0m_MAXLINE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/socket.py\u001B[0m in \u001B[0;36mreadinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    703\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 704\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv_into\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    705\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/ssl.py\u001B[0m in \u001B[0;36mrecv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1241\u001B[0m                   self.__class__)\n\u001B[0;32m-> 1242\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnbytes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1243\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/ssl.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1099\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mbuffer\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1100\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sslobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbuffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1101\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mProtocolError\u001B[0m: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mConnectionError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/weaviate/schema/crud_schema.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, class_name)\u001B[0m\n\u001B[1;32m    550\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 551\u001B[0;31m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_connection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    552\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mRequestsConnectionError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mconn_err\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/weaviate/connect/connection.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, path, params, external_url)\u001B[0m\n\u001B[1;32m    538\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 539\u001B[0;31m         return self._session.get(\n\u001B[0m\u001B[1;32m    540\u001B[0m             \u001B[0murl\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrequest_url\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/requests/sessions.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, url, **kwargs)\u001B[0m\n\u001B[1;32m    599\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msetdefault\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"allow_redirects\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 600\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"GET\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    601\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/requests/sessions.py\u001B[0m in \u001B[0;36mrequest\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    586\u001B[0m         \u001B[0msend_kwargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msettings\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 587\u001B[0;31m         \u001B[0mresp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0msend_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    588\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/requests/sessions.py\u001B[0m in \u001B[0;36msend\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    700\u001B[0m         \u001B[0;31m# Send the request\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 701\u001B[0;31m         \u001B[0mr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0madapter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    702\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/requests/adapters.py\u001B[0m in \u001B[0;36msend\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    500\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mProtocolError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mOSError\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 501\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mConnectionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrequest\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    502\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mConnectionError\u001B[0m: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mConnectionError\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/68/8hrdhbcs24z7sr41_6qzmxkw0000gn/T/ipykernel_59774/1013639117.py\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mvector_store\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mWeaviate\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_documents\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdocuments\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0membeddings\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclient\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mclient\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;32mexcept\u001B[0m \u001B[0mConnectionError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Unexpected status code: {e.status_code}, with response body: {e.response_body}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/langchain/vectorstores/base.py\u001B[0m in \u001B[0;36mfrom_documents\u001B[0;34m(cls, documents, embedding, **kwargs)\u001B[0m\n\u001B[1;32m    415\u001B[0m         \u001B[0mtexts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpage_content\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0md\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdocuments\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    416\u001B[0m         \u001B[0mmetadatas\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmetadata\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0md\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdocuments\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 417\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_texts\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtexts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0membedding\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetadatas\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmetadatas\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    418\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    419\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mclassmethod\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/langchain/vectorstores/weaviate.py\u001B[0m in \u001B[0;36mfrom_texts\u001B[0;34m(cls, texts, embedding, metadatas, **kwargs)\u001B[0m\n\u001B[1;32m    413\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    414\u001B[0m         \u001B[0;31m# check whether the index already exists\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 415\u001B[0;31m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mschema\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontains\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mschema\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    416\u001B[0m             \u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mschema\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcreate_class\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mschema\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    417\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/weaviate/schema/crud_schema.py\u001B[0m in \u001B[0;36mcontains\u001B[0;34m(self, schema)\u001B[0m\n\u001B[1;32m    367\u001B[0m         \"\"\"\n\u001B[1;32m    368\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 369\u001B[0;31m         \u001B[0mloaded_schema\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    370\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    371\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mschema\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/lib/python3.9/site-packages/weaviate/schema/crud_schema.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, class_name)\u001B[0m\n\u001B[1;32m    551\u001B[0m             \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_connection\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    552\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mRequestsConnectionError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mconn_err\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 553\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mRequestsConnectionError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Schema could not be retrieved.\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mconn_err\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    554\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstatus_code\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;36m200\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    555\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mUnexpectedStatusCodeException\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Get schema\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mConnectionError\u001B[0m: Schema could not be retrieved."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vector_store = Weaviate.from_documents(documents, embeddings, client=client)\n",
    "except ConnectionError as e:\n",
    "    print(f\"Unexpected status code: {e.status_code}, with response body: {e.response_body}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 848208 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 892640 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 816446 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 873219 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 919857 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 839117 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 880771 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 916650 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 837318 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 883076 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 934967 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 857556 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 855821 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 920635 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 844941 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 876004 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 899340 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 937078 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 861683 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 885022 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 914416 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 941587 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 861058 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 906781 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 827823 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 889466 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 917949 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 842199 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 843786 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 873620 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 924527 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 847553 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 895250 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 815475 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 894912 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-text-embedding-ada-002 in organization org-hIGwihMGYwCXLfkEAXet778V on tokens per min. Limit: 1000000 / min. Current: 818130 / min. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vectordb = FAISS.from_documents(documents, embeddings)\n",
    "except ConnectionError as e:\n",
    "    print(f\"Unexpected status code: {e.status_code}, with response body: {e.response_body}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local FAISS index has been successfully saved.\n"
     ]
    }
   ],
   "source": [
    "vectordb.save_local(\"faiss_index\")\n",
    "\n",
    "print('Local FAISS index has been successfully saved.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# Example Search\n",
    "query = \"What products does Apple sell?\"\n",
    "docs = vectordb.similarity_search(query)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "Document(page_content='product.\\n\\n(2)\\n\\nWearables, Home and Accessories net sales include sales of AirPods, Apple TV, Apple Watch, Beats products, HomePod mini and accessories.\\n\\n(3)\\n\\nServices net sales include sales from the Company’s advertising, AppleCare, cloud, digital content, payment and other services.\\n\\nServices net sales also include amortization of the deferred value of services bundled in the sales price of certain products.\\n\\niPhone\\n\\niPhone net sales increased during 2022 compared to 2021 due primarily to higher net sales from the Company’s new iPhone models released since the beginning of the fourth quarter of 2021.\\n\\nMac\\n\\nMac net sales increased during 2022 compared to 2021 due primarily to higher net sales of laptops.\\n\\niPad\\n\\niPad net\\n\\nsales decreased during 2022 compared to 2021 due primarily to lower net sales of iPad Pro.\\n\\nWearables, Home and Accessories', metadata={'company': 'Apple Inc.', 'date': '20221028', 'sic': 'ELECTRONIC COMPUTERS [3571]', 'state': 'CA', 'title': 'Financial Statements and Supplementary Data'})"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
